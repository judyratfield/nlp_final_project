{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf8181e-4569-4243-918e-288f80882da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Path</th>\n",
       "      <th>Predicted Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jel_recordings/02.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jel_recordings/16.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jel_recordings/17.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jel_recordings/03.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jel_recordings/15.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jel_recordings/01.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jel_recordings/14.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jel_recordings/10.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jel_recordings/04.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jel_recordings/05.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jel_recordings/11.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jel_recordings/07.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jel_recordings/13.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jel_recordings/12.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jel_recordings/06.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jel_recordings/23.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jel_recordings/22.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jel_recordings/20.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jel_recordings/08.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jel_recordings/09.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jel_recordings/21.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jel_recordings/19.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jel_recordings/25.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jel_recordings/24.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jel_recordings/18.wav</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File Path Predicted Emotion\n",
       "0   jel_recordings/02.wav               sad\n",
       "1   jel_recordings/16.wav             angry\n",
       "2   jel_recordings/17.wav               sad\n",
       "3   jel_recordings/03.wav           disgust\n",
       "4   jel_recordings/15.wav             angry\n",
       "5   jel_recordings/01.wav           disgust\n",
       "6   jel_recordings/14.wav              fear\n",
       "7   jel_recordings/10.wav             angry\n",
       "8   jel_recordings/04.wav           disgust\n",
       "9   jel_recordings/05.wav             angry\n",
       "10  jel_recordings/11.wav              fear\n",
       "11  jel_recordings/07.wav              fear\n",
       "12  jel_recordings/13.wav             angry\n",
       "13  jel_recordings/12.wav              fear\n",
       "14  jel_recordings/06.wav              fear\n",
       "15  jel_recordings/23.wav              fear\n",
       "16  jel_recordings/22.wav             angry\n",
       "17  jel_recordings/20.wav               sad\n",
       "18  jel_recordings/08.wav             angry\n",
       "19  jel_recordings/09.wav           disgust\n",
       "20  jel_recordings/21.wav             angry\n",
       "21  jel_recordings/19.wav              fear\n",
       "22  jel_recordings/25.wav              fear\n",
       "23  jel_recordings/24.wav             angry\n",
       "24  jel_recordings/18.wav               sad"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Audio Signals Classification - This notebook loads a trained model and classifies all WAV files in a specified folder.\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('emotion_recognition_model.h5')\n",
    "\n",
    "# Define feature extraction function\n",
    "def extract_features(data, sample_rate):\n",
    "    result = np.array([])\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result = np.hstack((result, zcr))\n",
    "    \n",
    "    # Chroma STFT\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft))\n",
    "    \n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc))\n",
    "    \n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms))\n",
    "    \n",
    "    # Mel Spectrogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to classify audio files in a folder\n",
    "def classify_audio_files(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    X = []\n",
    "    file_paths = []\n",
    "\n",
    "    for file in file_list:\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data, sample_rate = librosa.load(file_path, duration=2.5, offset=0.6)\n",
    "            features = extract_features(data, sample_rate)\n",
    "            X.append(features)\n",
    "            file_paths.append(file_path)\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = np.expand_dims(X, axis=2)\n",
    "\n",
    "    # Predict the emotions\n",
    "    predictions = model.predict(X)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Decode the predicted labels\n",
    "    emotion_dict = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "    predicted_emotions = [emotion_dict[label] for label in predicted_labels]\n",
    "\n",
    "    # Create a DataFrame to display the results\n",
    "    results_df = pd.DataFrame({'File Path': file_paths, 'Predicted Emotion': predicted_emotions})\n",
    "    return results_df\n",
    "\n",
    "# Specify the folder containing the WAV files\n",
    "folder_path = 'jel_recordings'\n",
    "\n",
    "# Classify the audio files in the folder\n",
    "results_df = classify_audio_files(folder_path)\n",
    "\n",
    "# Display the results\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb24aec-2b2c-477f-a58e-8b46dbb1327e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
